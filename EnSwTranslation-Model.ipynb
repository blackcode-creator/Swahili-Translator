{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66dcb86",
   "metadata": {},
   "source": [
    "#### 1.0 Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7d8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16936dc2",
   "metadata": {},
   "source": [
    "#### 1.1 loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454a75aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/starlabs/.cache/huggingface/datasets/csv/default-b6e27a0700ebebe3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_dataset(\"csv\", data_files=\"./dataset/enswdataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84f787",
   "metadata": {},
   "source": [
    "#### 1.2 Viewing the dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e4e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset object:\n",
      "\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['English sentence', 'Swahii Translation'],\n",
      "        num_rows: 8492\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset object:\\n\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d55568",
   "metadata": {},
   "source": [
    "#### 1.3 Viewing the split dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4d828f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/starlabs/.cache/huggingface/datasets/csv/default-b6e27a0700ebebe3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-82a620d671faa70e.arrow and /home/starlabs/.cache/huggingface/datasets/csv/default-b6e27a0700ebebe3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-0a0d7c836fcb93ae.arrow\n"
     ]
    }
   ],
   "source": [
    "split_df = df['train'].train_test_split(train_size=0.9, seed=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2bcd96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split datasets:\n",
      "\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['English sentence', 'Swahii Translation'],\n",
      "        num_rows: 7642\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['English sentence', 'Swahii Translation'],\n",
      "        num_rows: 850\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSplit datasets:\\n\\n\", split_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa9732",
   "metadata": {},
   "source": [
    "#### 1.4  Loading the tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3a51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-swc\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b948875",
   "metadata": {},
   "source": [
    "#### 1.5 Set the maximum sequence length and define the preprocessing function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81abdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6eb9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples['English sentence']\n",
    "    targets = examples['Swahii Translation']\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=max_length, padding=\"max_length\", truncation=True\n",
    "    )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce67a0",
   "metadata": {},
   "source": [
    "#### 1.6 Preprocess the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5b6c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/starlabs/.cache/huggingface/datasets/csv/default-b6e27a0700ebebe3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-71dbe1ab21e3eb56_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = split_df['train'].map(\n",
    "    preprocess_function, batched=True, num_proc=4, remove_columns=[\"English sentence\", \"Swahii Translation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eccdc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/starlabs/.cache/huggingface/datasets/csv/default-b6e27a0700ebebe3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fb0df2806c8661f8_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = split_df['test'].map(\n",
    "    preprocess_function, batched=True, num_proc=4, remove_columns=[\"English sentence\", \"Swahii Translation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373c2a0",
   "metadata": {},
   "source": [
    "#### 1.7 Define the training arguments and create the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c5c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./models/',\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129cef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08180229",
   "metadata": {},
   "source": [
    "#### 1.8 train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb6faed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='956' max='956' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [956/956 3:54:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=956, training_loss=0.10757422347447862, metrics={'train_runtime': 14086.3703, 'train_samples_per_second': 1.085, 'train_steps_per_second': 0.068, 'total_flos': 518102609559552.0, 'train_loss': 0.10757422347447862, 'epoch': 2.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ca960",
   "metadata": {},
   "source": [
    "#### 1.9 evaluate the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1033daf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 03:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08861713856458664, 'eval_runtime': 240.7144, 'eval_samples_per_second': 3.531, 'eval_steps_per_second': 0.224, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "result = trainer.evaluate()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2611cd",
   "metadata": {},
   "source": [
    "#### 2.0 export the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72875f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/tokenizer_config.json',\n",
       " './models/special_tokens_map.json',\n",
       " './models/vocab.json',\n",
       " './models/source.spm',\n",
       " './models/target.spm',\n",
       " './models/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./models\")\n",
    "tokenizer.save_pretrained(\"./models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88972a27",
   "metadata": {},
   "source": [
    "#### 2.1 creating a pipeline for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0336873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"./models\",\n",
    "    tokenizer=\"./models\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086194b",
   "metadata": {},
   "source": [
    "#### 2.2 prompt the user to enter a sentence for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5976a951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an English sentence for translation to Swahili (type 'exit' to quit): prints a feedback message before breaking\n",
      "Translated text: linachapisha ujumbe wa haraka wa mama kabla ya kuvunja\n",
      "Enter an English sentence for translation to Swahili (type 'exit' to quit): exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    text = input(\"Enter an English sentence for translation to Swahili (type 'exit' to quit): \")\n",
    "    if text == \"exit\":\n",
    "        break\n",
    "    translated_text = translator(text, max_length=max_length)[0]['generated_text']\n",
    "    print(f\"Translated text: {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b4fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
